{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cd05c9-863e-4136-9181-695450f77066",
   "metadata": {},
   "source": [
    "## 1. What is the concept of cyclical momentum?\n",
    "**Answer:**\n",
    "Cyclical momentum is a training technique where the momentum parameter in an optimizer oscillates between a minimum and maximum value during training. This approach can help the model escape local minima and explore the loss surface more effectively, potentially leading to better convergence. By periodically decreasing momentum, the optimizer can take larger steps when needed and then refine its path with increased momentum.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. What callback keeps track of hyperparameter values (along with other data) during training?\n",
    "**Answer:**\n",
    "The `Learner` object in many deep learning frameworks, such as fastai, includes a `Recorder` callback that keeps track of various metrics, including hyperparameter values, training loss, validation loss, and other relevant statistics during training. This data can be used to analyze and fine-tune the training process.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. In the color dim plot, what does one column of pixels represent?\n",
    "**Answer:**\n",
    "In a color dim plot, one column of pixels represents the activations of a particular feature map (or channel) across different spatial positions in an image. Each row corresponds to a different spatial position, and the intensity of the color indicates the strength of the activation.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. In color dim, what does \"poor teaching\" look like? What is the reason for this?\n",
    "**Answer:**\n",
    "\"Poor teaching\" in a color dim plot typically appears as uninformative or noisy activations, where the feature maps do not capture meaningful patterns or fail to distinguish between different inputs. This can happen if the model is not learning effectively, often due to issues such as a learning rate that is too high or low, poor initialization, or insufficient regularization.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Does a batch normalization layer have any trainable parameters?\n",
    "**Answer:**\n",
    "Yes, a batch normalization layer has two trainable parameters: `gamma` and `beta`. The `gamma` parameter scales the normalized output, and the `beta` parameter shifts it. These parameters allow the network to maintain flexibility and undo the normalization if necessary.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. In batch normalization during preparation, what statistics are used to normalize? What about during the validation process?\n",
    "**Answer:**\n",
    "During training (preparation), batch normalization uses the mean and variance of the current batch to normalize the inputs. During validation (or inference), it uses the moving average of the mean and variance, computed during training, to ensure consistency and stability in the predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Why do batch normalization layers help models generalize better?\n",
    "**Answer:**\n",
    "Batch normalization layers help models generalize better by reducing internal covariate shift, which stabilizes the learning process and allows for higher learning rates. This results in faster convergence and less sensitivity to initialization. Additionally, the regularization effect of batch normalization, due to the noise introduced during batch-wise normalization, helps prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Explain the difference between MAX POOLING and AVERAGE POOLING.\n",
    "**Answer:**\n",
    "**Max Pooling:**\n",
    "- Selects the maximum value from each patch of the feature map.\n",
    "- Helps in retaining the most prominent features while reducing spatial dimensions.\n",
    "\n",
    "**Average Pooling:**\n",
    "- Calculates the average value of each patch of the feature map.\n",
    "- Provides a smoother and more generalized feature map by averaging out the values.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. What is the purpose of the POOLING LAYER?\n",
    "**Answer:**\n",
    "The pooling layer is used to reduce the spatial dimensions (width and height) of the input feature maps while retaining the most important features. This helps in reducing the computational load and the number of parameters, making the model more efficient and less prone to overfitting. Pooling layers also provide some degree of translational invariance, helping the model to better recognize objects regardless of their position in the image.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Why do we end up with Completely CONNECTED LAYERS?\n",
    "**Answer:**\n",
    "We end up with fully connected (dense) layers at the end of a convolutional neural network to combine the features extracted by the convolutional layers and pooling layers into a final classification or regression decision. Fully connected layers aggregate the information from all the feature maps and allow the network to learn complex combinations of these features, ultimately leading to the final output.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. What do you mean by PARAMETERS?\n",
    "**Answer:**\n",
    "In the context of neural networks, parameters refer to the weights and biases that are learned during training. These parameters define how the input data is transformed as it passes through the network layers, ultimately determining the model's predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. What formulas are used to measure these PARAMETERS?\n",
    "**Answer:**\n",
    "The number of parameters in a neural network can be calculated using the following formulas:\n",
    "\n",
    "- **For a fully connected (dense) layer:**\n",
    "  \\[\n",
    "  \\text{Number of Parameters} = (\\text{Number of Inputs} \\times \\text{Number of Outputs}) + \\text{Number of Outputs (Biases)}\n",
    "  \\]\n",
    "\n",
    "- **For a convolutional layer:**\n",
    "  \\[\n",
    "  \\text{Number of Parameters} = (\\text{Number of Filters} \\times \\text{Filter Height} \\times \\text{Filter Width} \\times \\text{Number of Input Channels}) + \\text{Number of Filters (Biases)}\n",
    "  \\]\n",
    "\n",
    "These formulas account for both the weights and biases in each layer.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3e248-afee-477d-92e9-fc735f4dbaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
